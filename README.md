# 인공지능 Project 1

## 이름 : 이준휘

## 학번 : 2018202046

## 교수 : 박철수 교수님

## 분반 : 금 3, 4


## 1. Introduction

#### 해당 과제는 PCA를 이용하여 얼굴을 인식하는 과정을 시뮬레이션을 수행한다. LWF 얼굴

```
DB를 이용하여 PCA를 통해 eigen-face를 출력하여 보며, KNN 모델을 학습시키는 과정에서
PCA Whitening의 여부를 통한 정확도 차이를 비교한다. 또한 주성분의 개수의 차이를 두어
얼굴 이미지를 재구성하고 결과를 확인한다. KNN 모델은 train과 test 데이터에 PCA를 적용
하여 KNN 모델을 생성하고 학습시켜 결과를 설명한다. 또한 해당 결과와 CNN을 이용한
결과와 성능을 비교한다.
```
## 2. Algorithm

### a. PCA

```
PCA란 Principal Component Analysis의 약자로 인공지능에서 많이 쓰이는 알고리즘 중 하
나다. PCA는 크게 Compression과 Classification으로 핵심을 나눌 수 있다, Compression은
dimensions을 줄인다는 의미로, 기존의 데이터보다 차원의 개수를 줄여 데이터를 본다
는 의미다. Classification은 데이터의 패턴을 확인하는 것이다. PCA는 분포가 가장 큰 방
향을 탐색하여 탐색한 정보와 가장 관련이 없는 방향부터 탐색을 수행한다. 위의 과
정은 Covariance를 행렬곱을 통해 구할 수 있으며 이에 대한 Eigenvalue를 찾는 과정을
통해 고유 벡터를 찾을 수 있다. 해당 과정은 sklearn.decomposition의 PCA 함수를 통
해 구현되어 있으며 여기서 component의 개수와 whitening 옵션, random state를 결정여
모델을 fitting, 적용시킬 수 있다. whitening이란 기저 벡터의 값을 eigenvalue 값으로 나
누어 정규화하는 기법을 의미한다. 즉 이는 만약 데이터가 multivariable gaussian 분포
를 보일 경우 평균이 0 이고 공분산이 I(단위 행렬)인 모습을 가진다.
```
### b. KNN

```
KNN이란 K-nearest neighbors의 약자로 분류, 회귀 문제 등 다양한 문제에 자주 쓰이는
알고리즘이다. 이 때 k가 의미하는 것은 이웃의 숫자를 뜻하며 k만큼의 이웃을 지정
하고 그 이웃들의 값을 토대로 계산한다. KNN 분석을 할 때 K를 너무 낮게 설정할 경
우 overfitting 문제가 발생하기 때문에 주의해야 하며, K를 너무 높게 줄 경우 데이터
가 일반화되기 때문에 유의미한 분석이 어려울 수 있다. K를 선택한 후에는 기준이 되
는 데이터와 데이터 간의 유클리드 거리를 계산하고, 가장 가까운 K개의 이웃을 선택
하며, 이러한 레코드들의 레이블을 기준으로 분류나 회귀값을 예측한다.
```
```
sklearn.neigbors에서 제공하는 KNeighborsClassifier 함수를 이용할 경우 k의 초기값을 설
정할 수 있으며 fit() 함수를 통해 최적의 K값을 찾는다. 또한 score 함수를 통해 정확
성을 체크할 수 있다.
```
### c. CNN

```
CNN은 Convolutional Nueral Network의 약자로 보통 이미지를 분석하기 위해 패턴을 찾
는데 유용한 알고리즘이다. 이미지의 공간정보를 유지하며 학습하며, 필터링 기법을
인공 신경망(NN)에 적용하여 이미지를 더욱 효과적으로 처리한다. CNN이 나오기 이전
의 이미지 인식은 2 차원으로 이미지를 1 차원 배열로 바꾼 후 FNN 신경망을 통핵 학
습시키는 것이였다. 이는 인접 픽셀 간의 상관관계가 무시된다는 문제가 있었다. 벡터
```

#### 형태로 표현된 데이터를 입력받기 위해 이미지를 벡터화 해야 하는데 이 때 인접 필

#### 셀 간의 상관관계를 잃어 정보의 손실이 발생하였다. CNN은 이미지의 형태를 보존하

#### 도록 행렬 형태의 데이터를 입력 받기 때문에 이러한 정보 손실을 방지할 수 있다.

```
CNN은 여러 계층을 쌓는 구조로 되어있다. Convolution Layer에서는 이미지에 필터링 기
법을 적용하며, Pooling layer에서는 이미지의 작은 부분들을 대표 스칼라 값으로 변환
시켜 이미지 크기를 줄이는 과정과 같은 다양한 역할을 수행한다.
```
## 3. Result

```
위의 그림은 sklearn으로부터 lfw people 데이터를 불러오는 모습이다. 각 인물의 최소
사진 수는 20 으로 설정되었으며 resize는 사진의 크기로 0.7배로 조정하였다. 값이 정상
적으로 들어갔는지 확인하기 위해 people의 모양과 class의 개수를 출력하였을 때 다음
과 같이 나왔다. 해당 image는 87 * 65 크기의 사진이 3023 개 존재하며 이름의 종류는
62 개가 존재한다. target에는 각 사진에 해당하는 이름 순서가 저장되어 있다. 각 인자
에 대한 설명은 DESCR를 통해 확인할 수 있다.
```

위의 사진은 각 이름 class에 해당하는 사진이 몇 개가 있는지 확인하는 과정이다.
numpy의 bincount 함수를 통해 사진의 빈도를 알아내고 이를 출력하였으며, 이 때 사
진의 개수는 각 인물마다 편차가 있는 것으로 확인된다. 인물의 최소 개수를 알아내기
위해 argmin()함수를 통해 최소인 counts를 찾아내었고, 해당하는 idx 번호를 탐색하였
을 때 20 개의 사진을 가진 Angelina Jolie이 나왔다.

#### PCA에서 인물마다 사진의 개수가 다른 편차를 없애기 위해 가장 작은 사진을 가진 인

물을 선택하는 과정이 나온다. idx 배열을 target의 크기만큼 0 을 가지도록 설정한 후
반복문을 통해 min_count에 해당하는 배열까지만을 1 로 설정한다. 이후 x_people과
y_people 변수를 만들며 이는 각 인물에서 20 장만 선택된 idx 배열을 통해 데이터를 옮
긴다.


PCA 함수를 통해 component의 개수를 100 으로 제한하며 whitening 옵션을 켠 상태로
PCA를 수행하였을 때 다음과 같은 결과가 나왔다. pca에서 측정된 분산은 다음과 같이
크기 순으로 정렬되어 있다.

다음 사진은 각 component를 출력하는 모습이다. 다음과 같이 얼굴의 고유 성분이 추
출되어 나온 것을 확인할 수 있다. 이를 통해 PCA가 정상적으로 구현되었음을 알 수
있다.

해당 사진은 기존 사진 사람 데이터를 늘려서 train과 test로 구분하기 위해 sklearn의


MinMaxScaler를 이용한다. 이를 통해 x_people을 늘린 데이터를 사용한다. train_test_split
함수는 test와 train으로 데이터를 나누어주는 함수다. 이를 통해 x_train, x_test, y_train,
y_test로 데이터를 나누어준다.

위의 사진은 component의 개수의 따라 이미지를 재구성하였을 때의 차이를 보는 함수
를 만든 것이다. 위의 사진을 보았을 때 compenent의 수가 많아질 수록 이미지를 재구
성하였을 때 더욱 원본에 가까워지는 것을 확인할 수 있다.


해당 사진은 whitening 옵션을 적용하지 않을 때의 KNN 모델을 확인하는 것이다. KNN
모델은 KneigborClassifier()함수를 통해 불러올 수 있으며 fit를 통해 해당 데이터를 학습
시킬 수 있다. whitening이 적용되지 않은 pca를 사용한 knn의 정확도는 약 0.065로 상
당히 낮게 나온 모습이다.

해당 사진은 whitening 옵션을 적용하였을 때의 KNN 모델을 확인하는 것이다. whitening
이 적용된 knn 모델의 정확도는 0.08 2 이 나오는 모습을 확인할 수 있다. 이를 통해
whitening을 적용하였을 때 정확도가 상승한다는 것을 알 수 있다.

다음 그림은 CNN 모델을 학습하는 과정을 보이는 코드다. X_people과 Y_people은 전체
데이터를 사용할 예정이며, X_people을 CNN에 넣기 위해서는 형태를 이에 맞게 4 차원
으로 변경시킬 필요가 있다. 사진의 개수, 사진의 크기, gray_scale의 이미지임으로 마지
막을 1 로 설정한 형태로 모양을 변경시킨다. face_labels 변수는 Y_people을 one-hot
encoding을 통해 형태를 변형한 모습을 갖는다. one-hot encoding은 keras에서 제공하는
to_categorial 함수를 이용한다. 이 데이터를 이전에 사용한 train_test_split 함수를 통해
train과 test로 분리한다.


```
위의 사진은 임의의 CNN layer를 적층하는 모습이다. CNN 모델의 사용은 Sequential 함
수를 통해 할 수 있으며 add()함수를 통해 적층할 수 있다. Conv2D layer은 특정 filter size
로 matrix convolution을 수행하며, MaxPooling을 통해 값을 조정한다. Flatten은 1 차원 데
이터로 조정시키는 역할을 수행하며, Dense를 통해 특정 개수로 출력을 모아준다. 해당
모델이 다음과 같이 정상적으로 생성되었음을 보았다.
```
```
Model을 fit함수를 이용해 epoch, batch size를 설정하여 학습시킨다. epoch는 학습 횟수를
나타내며, batch size는 트레이닝 그룹을 작게 나누었을 때 하나의 소그룹에 속하는 데이
터 수다. 모델을 test 데이터를 통해 평가하였을 때 loss는 4.6, accuracy는 0.5가 나온다.
이전의 pca를 적용한 KNN 모델(0.08)보다 정확도가 훨씬 높게 상승하였다.
```
## 4. Consideration

#### 해당 과제를 통해 PCA, KNN, CNN을 기존 라이브러리를 통해 손쉽게 구현할 수 있음을 알

```
수 있다. PCA의 whitening 옵션을 사용하는 것이 정확도가 상승한다는 사실을 알 수 있다.
또한 PCA를 사용한 KNN의 모델은 정확도가 0.08이 나오고 CNN 모델은 정확도가 0.5가 나
오기에 두 모델 중 하나의 모델을 선택한다면 CNN 모델을 사용하는 것이 맞다는 결론을
낼 수 있다. 과제를 통해 이러한 다양한 사실을 직접 실습을 통해 체험할 수 있는 과제였
다.
```


